{
  "best_global_step": 10004,
  "best_metric": 1.0,
  "best_model_checkpoint": "/content/legalbert_hss_ner_final/checkpoint-10004",
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 10004,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.039996000399960006,
      "grad_norm": Infinity,
      "learning_rate": 1.6486261448792674e-06,
      "loss": 5.1051,
      "step": 100
    },
    {
      "epoch": 0.07999200079992001,
      "grad_norm": 4.13748836517334,
      "learning_rate": 3.2972522897585347e-06,
      "loss": 4.8344,
      "step": 200
    },
    {
      "epoch": 0.11998800119988001,
      "grad_norm": 4.275408744812012,
      "learning_rate": 4.962531223980017e-06,
      "loss": 4.1063,
      "step": 300
    },
    {
      "epoch": 0.15998400159984003,
      "grad_norm": 5.461848258972168,
      "learning_rate": 6.6278101582015e-06,
      "loss": 3.0644,
      "step": 400
    },
    {
      "epoch": 0.1999800019998,
      "grad_norm": 4.699275493621826,
      "learning_rate": 8.29308909242298e-06,
      "loss": 1.9813,
      "step": 500
    },
    {
      "epoch": 0.23997600239976002,
      "grad_norm": 3.3280866146087646,
      "learning_rate": 9.958368026644463e-06,
      "loss": 1.1141,
      "step": 600
    },
    {
      "epoch": 0.27997200279972,
      "grad_norm": 1.662174940109253,
      "learning_rate": 1.1623646960865946e-05,
      "loss": 0.5165,
      "step": 700
    },
    {
      "epoch": 0.31996800319968005,
      "grad_norm": 0.6125645637512207,
      "learning_rate": 1.3288925895087428e-05,
      "loss": 0.2338,
      "step": 800
    },
    {
      "epoch": 0.35996400359964004,
      "grad_norm": 0.37669748067855835,
      "learning_rate": 1.495420482930891e-05,
      "loss": 0.1192,
      "step": 900
    },
    {
      "epoch": 0.3999600039996,
      "grad_norm": 0.3143245279788971,
      "learning_rate": 1.6619483763530392e-05,
      "loss": 0.0757,
      "step": 1000
    },
    {
      "epoch": 0.43995600439956006,
      "grad_norm": 0.2235027551651001,
      "learning_rate": 1.8284762697751875e-05,
      "loss": 0.0538,
      "step": 1100
    },
    {
      "epoch": 0.47995200479952005,
      "grad_norm": 0.14942054450511932,
      "learning_rate": 1.9950041631973358e-05,
      "loss": 0.0409,
      "step": 1200
    },
    {
      "epoch": 0.51994800519948,
      "grad_norm": 0.13650009036064148,
      "learning_rate": 1.9994008874121593e-05,
      "loss": 0.032,
      "step": 1300
    },
    {
      "epoch": 0.55994400559944,
      "grad_norm": 0.08823555707931519,
      "learning_rate": 1.9975296305611596e-05,
      "loss": 0.0263,
      "step": 1400
    },
    {
      "epoch": 0.5999400059994,
      "grad_norm": 0.08691144734621048,
      "learning_rate": 1.9943880393288994e-05,
      "loss": 0.0221,
      "step": 1500
    },
    {
      "epoch": 0.6399360063993601,
      "grad_norm": 0.08386600762605667,
      "learning_rate": 1.989980114470075e-05,
      "loss": 0.0189,
      "step": 1600
    },
    {
      "epoch": 0.6799320067993201,
      "grad_norm": 0.0645931139588356,
      "learning_rate": 1.9843114693903703e-05,
      "loss": 0.0163,
      "step": 1700
    },
    {
      "epoch": 0.7199280071992801,
      "grad_norm": 0.0885581225156784,
      "learning_rate": 1.9773893229978954e-05,
      "loss": 0.0146,
      "step": 1800
    },
    {
      "epoch": 0.7599240075992401,
      "grad_norm": 0.047789640724658966,
      "learning_rate": 1.969222490510048e-05,
      "loss": 0.013,
      "step": 1900
    },
    {
      "epoch": 0.7999200079992,
      "grad_norm": 0.05143123120069504,
      "learning_rate": 1.959821372227509e-05,
      "loss": 0.0119,
      "step": 2000
    },
    {
      "epoch": 0.83991600839916,
      "grad_norm": 0.047859132289886475,
      "learning_rate": 1.949197940289662e-05,
      "loss": 0.0105,
      "step": 2100
    },
    {
      "epoch": 0.8799120087991201,
      "grad_norm": 0.04203622788190842,
      "learning_rate": 1.9373657234283102e-05,
      "loss": 0.0097,
      "step": 2200
    },
    {
      "epoch": 0.9199080091990801,
      "grad_norm": 0.03876475244760513,
      "learning_rate": 1.9243397897391016e-05,
      "loss": 0.0088,
      "step": 2300
    },
    {
      "epoch": 0.9599040095990401,
      "grad_norm": 0.04834543168544769,
      "learning_rate": 1.9101367274926074e-05,
      "loss": 0.0081,
      "step": 2400
    },
    {
      "epoch": 0.9999000099990001,
      "grad_norm": 0.02676929347217083,
      "learning_rate": 1.8947746240094817e-05,
      "loss": 0.0076,
      "step": 2500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.003092322964221239,
      "eval_macro_f1": 0.9881513449086614,
      "eval_overall_accuracy": 0.9993903567386102,
      "eval_overall_f1": 0.9847860139356512,
      "eval_overall_precision": 0.9700280211399993,
      "eval_overall_recall": 1.0,
      "eval_runtime": 110.1117,
      "eval_samples_per_second": 90.826,
      "eval_steps_per_second": 5.685,
      "step": 2501
    },
    {
      "epoch": 1.0395960403959603,
      "grad_norm": 0.02157808095216751,
      "learning_rate": 1.878273042626617e-05,
      "loss": 0.0069,
      "step": 2600
    },
    {
      "epoch": 1.0795920407959203,
      "grad_norm": 0.019140193238854408,
      "learning_rate": 1.8606529977836198e-05,
      "loss": 0.0064,
      "step": 2700
    },
    {
      "epoch": 1.1195880411958805,
      "grad_norm": 0.01849236898124218,
      "learning_rate": 1.8419369282613306e-05,
      "loss": 0.006,
      "step": 2800
    },
    {
      "epoch": 1.1595840415958405,
      "grad_norm": 0.016286376863718033,
      "learning_rate": 1.8221486686064822e-05,
      "loss": 0.0056,
      "step": 2900
    },
    {
      "epoch": 1.1995800419958005,
      "grad_norm": 0.016826635226607323,
      "learning_rate": 1.80131341877887e-05,
      "loss": 0.0052,
      "step": 3000
    },
    {
      "epoch": 1.2395760423957605,
      "grad_norm": 0.021899530664086342,
      "learning_rate": 1.7794577120596988e-05,
      "loss": 0.0049,
      "step": 3100
    },
    {
      "epoch": 1.2795720427957205,
      "grad_norm": 0.017510537058115005,
      "learning_rate": 1.7566093812619715e-05,
      "loss": 0.0047,
      "step": 3200
    },
    {
      "epoch": 1.3195680431956804,
      "grad_norm": 0.012714560143649578,
      "learning_rate": 1.7327975232859483e-05,
      "loss": 0.0044,
      "step": 3300
    },
    {
      "epoch": 1.3595640435956404,
      "grad_norm": 0.012075723148882389,
      "learning_rate": 1.7080524620648148e-05,
      "loss": 0.0041,
      "step": 3400
    },
    {
      "epoch": 1.3995600439956004,
      "grad_norm": 0.013040605932474136,
      "learning_rate": 1.6824057099477524e-05,
      "loss": 0.0038,
      "step": 3500
    },
    {
      "epoch": 1.4395560443955604,
      "grad_norm": 0.0111386738717556,
      "learning_rate": 1.655889927569576e-05,
      "loss": 0.0036,
      "step": 3600
    },
    {
      "epoch": 1.4795520447955204,
      "grad_norm": 0.010329335927963257,
      "learning_rate": 1.6285388822580616e-05,
      "loss": 0.0034,
      "step": 3700
    },
    {
      "epoch": 1.5195480451954806,
      "grad_norm": 0.009395635686814785,
      "learning_rate": 1.6003874050319158e-05,
      "loss": 0.0033,
      "step": 3800
    },
    {
      "epoch": 1.5595440455954406,
      "grad_norm": 0.009291473776102066,
      "learning_rate": 1.5714713462441587e-05,
      "loss": 0.0031,
      "step": 3900
    },
    {
      "epoch": 1.5995400459954006,
      "grad_norm": 0.008169980719685555,
      "learning_rate": 1.5418275299274043e-05,
      "loss": 0.003,
      "step": 4000
    },
    {
      "epoch": 1.6395360463953605,
      "grad_norm": 0.010934371501207352,
      "learning_rate": 1.5114937068991766e-05,
      "loss": 0.0028,
      "step": 4100
    },
    {
      "epoch": 1.6795320467953205,
      "grad_norm": 0.007722221780568361,
      "learning_rate": 1.480508506686988e-05,
      "loss": 0.0027,
      "step": 4200
    },
    {
      "epoch": 1.7195280471952805,
      "grad_norm": 0.008529897779226303,
      "learning_rate": 1.4489113883343939e-05,
      "loss": 0.0026,
      "step": 4300
    },
    {
      "epoch": 1.7595240475952405,
      "grad_norm": 0.0073313964530825615,
      "learning_rate": 1.4167425901506755e-05,
      "loss": 0.0024,
      "step": 4400
    },
    {
      "epoch": 1.7995200479952005,
      "grad_norm": 0.006609325297176838,
      "learning_rate": 1.3840430784681452e-05,
      "loss": 0.0023,
      "step": 4500
    },
    {
      "epoch": 1.8395160483951605,
      "grad_norm": 0.006400610785931349,
      "learning_rate": 1.3508544954723252e-05,
      "loss": 0.0022,
      "step": 4600
    },
    {
      "epoch": 1.8795120487951205,
      "grad_norm": 0.007261412683874369,
      "learning_rate": 1.317219106171446e-05,
      "loss": 0.0021,
      "step": 4700
    },
    {
      "epoch": 1.9195080491950804,
      "grad_norm": 0.005673189181834459,
      "learning_rate": 1.2831797445727861e-05,
      "loss": 0.002,
      "step": 4800
    },
    {
      "epoch": 1.9595040495950404,
      "grad_norm": 0.0070224059745669365,
      "learning_rate": 1.2487797591344063e-05,
      "loss": 0.002,
      "step": 4900
    },
    {
      "epoch": 1.9995000499950004,
      "grad_norm": 0.006649626884609461,
      "learning_rate": 1.2140629575617402e-05,
      "loss": 0.0019,
      "step": 5000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0007946003461256623,
      "eval_macro_f1": 0.9989969380213284,
      "eval_overall_accuracy": 0.9999663864713685,
      "eval_overall_f1": 0.9991323170787401,
      "eval_overall_precision": 0.998266138599405,
      "eval_overall_recall": 1.0,
      "eval_runtime": 88.4779,
      "eval_samples_per_second": 113.034,
      "eval_steps_per_second": 7.075,
      "step": 5002
    },
    {
      "epoch": 2.0391960803919607,
      "grad_norm": 0.006964636035263538,
      "learning_rate": 1.1790735510193433e-05,
      "loss": 0.0018,
      "step": 5100
    },
    {
      "epoch": 2.0791920807919206,
      "grad_norm": 0.004856908693909645,
      "learning_rate": 1.1438560978288417e-05,
      "loss": 0.0017,
      "step": 5200
    },
    {
      "epoch": 2.1191880811918806,
      "grad_norm": 0.005874976050108671,
      "learning_rate": 1.1084554467247875e-05,
      "loss": 0.0017,
      "step": 5300
    },
    {
      "epoch": 2.1591840815918406,
      "grad_norm": 0.006640818901360035,
      "learning_rate": 1.0729166797406745e-05,
      "loss": 0.0018,
      "step": 5400
    },
    {
      "epoch": 2.199180081991801,
      "grad_norm": 0.005622712429612875,
      "learning_rate": 1.0372850547978562e-05,
      "loss": 0.0016,
      "step": 5500
    },
    {
      "epoch": 2.239176082391761,
      "grad_norm": 0.004897996783256531,
      "learning_rate": 1.0016059480704715e-05,
      "loss": 0.0015,
      "step": 5600
    },
    {
      "epoch": 2.279172082791721,
      "grad_norm": 0.006584134418517351,
      "learning_rate": 9.662814686156456e-06,
      "loss": 0.0015,
      "step": 5700
    },
    {
      "epoch": 2.319168083191681,
      "grad_norm": 0.005051221698522568,
      "learning_rate": 9.306430521155611e-06,
      "loss": 0.0016,
      "step": 5800
    },
    {
      "epoch": 2.359164083591641,
      "grad_norm": 0.004382043611258268,
      "learning_rate": 8.950929603256183e-06,
      "loss": 0.0014,
      "step": 5900
    },
    {
      "epoch": 2.399160083991601,
      "grad_norm": 0.0037034633569419384,
      "learning_rate": 8.596764655890881e-06,
      "loss": 0.0013,
      "step": 6000
    },
    {
      "epoch": 2.439156084391561,
      "grad_norm": 0.0047339703887701035,
      "learning_rate": 8.244386701160191e-06,
      "loss": 0.0013,
      "step": 6100
    },
    {
      "epoch": 2.479152084791521,
      "grad_norm": 0.003807526081800461,
      "learning_rate": 7.894244485464601e-06,
      "loss": 0.0012,
      "step": 6200
    },
    {
      "epoch": 2.519148085191481,
      "grad_norm": 0.0048436918295919895,
      "learning_rate": 7.5467839080348715e-06,
      "loss": 0.0012,
      "step": 6300
    },
    {
      "epoch": 2.559144085591441,
      "grad_norm": 0.0036329827271401882,
      "learning_rate": 7.2024474530881346e-06,
      "loss": 0.0011,
      "step": 6400
    },
    {
      "epoch": 2.599140085991401,
      "grad_norm": 0.003474242053925991,
      "learning_rate": 6.861673626332928e-06,
      "loss": 0.0011,
      "step": 6500
    },
    {
      "epoch": 2.639136086391361,
      "grad_norm": 0.004288085736334324,
      "learning_rate": 6.524896396540803e-06,
      "loss": 0.0015,
      "step": 6600
    },
    {
      "epoch": 2.679132086791321,
      "grad_norm": 0.0039715575985610485,
      "learning_rate": 6.192544642895622e-06,
      "loss": 0.0011,
      "step": 6700
    },
    {
      "epoch": 2.719128087191281,
      "grad_norm": 0.003163931192830205,
      "learning_rate": 5.86504160882434e-06,
      "loss": 0.0011,
      "step": 6800
    },
    {
      "epoch": 2.759124087591241,
      "grad_norm": 0.003664919873699546,
      "learning_rate": 5.542804363004815e-06,
      "loss": 0.0011,
      "step": 6900
    },
    {
      "epoch": 2.799120087991201,
      "grad_norm": 0.0030299683567136526,
      "learning_rate": 5.226243268237059e-06,
      "loss": 0.001,
      "step": 7000
    },
    {
      "epoch": 2.839116088391161,
      "grad_norm": 0.006247625686228275,
      "learning_rate": 4.915761458854261e-06,
      "loss": 0.001,
      "step": 7100
    },
    {
      "epoch": 2.879112088791121,
      "grad_norm": 0.0036353860050439835,
      "learning_rate": 4.611754327339145e-06,
      "loss": 0.001,
      "step": 7200
    },
    {
      "epoch": 2.919108089191081,
      "grad_norm": 0.002655300311744213,
      "learning_rate": 4.3146090207993995e-06,
      "loss": 0.0009,
      "step": 7300
    },
    {
      "epoch": 2.9591040895910408,
      "grad_norm": 0.003637060523033142,
      "learning_rate": 4.024703947943463e-06,
      "loss": 0.0009,
      "step": 7400
    },
    {
      "epoch": 2.9991000899910008,
      "grad_norm": 0.0038548270240426064,
      "learning_rate": 3.74240829718446e-06,
      "loss": 0.0009,
      "step": 7500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.00037650568992830813,
      "eval_macro_f1": 0.9996257148430391,
      "eval_overall_accuracy": 0.9999879698950161,
      "eval_overall_f1": 0.9996892877378318,
      "eval_overall_precision": 0.9993787684999086,
      "eval_overall_recall": 1.0,
      "eval_runtime": 88.8286,
      "eval_samples_per_second": 112.588,
      "eval_steps_per_second": 7.047,
      "step": 7503
    },
    {
      "epoch": 3.038796120387961,
      "grad_norm": 0.003686050418764353,
      "learning_rate": 3.4680815664860166e-06,
      "loss": 0.0009,
      "step": 7600
    },
    {
      "epoch": 3.0787921207879214,
      "grad_norm": 0.0026504797860980034,
      "learning_rate": 3.2020731055486533e-06,
      "loss": 0.0009,
      "step": 7700
    },
    {
      "epoch": 3.1187881211878814,
      "grad_norm": 0.0027805662248283625,
      "learning_rate": 2.9447216709198325e-06,
      "loss": 0.0008,
      "step": 7800
    },
    {
      "epoch": 3.1587841215878414,
      "grad_norm": 0.002207276877015829,
      "learning_rate": 2.6963549945941315e-06,
      "loss": 0.0008,
      "step": 7900
    },
    {
      "epoch": 3.1987801219878014,
      "grad_norm": 0.0018869534833356738,
      "learning_rate": 2.4572893666530005e-06,
      "loss": 0.0008,
      "step": 8000
    },
    {
      "epoch": 3.2387761223877614,
      "grad_norm": 0.003231652779504657,
      "learning_rate": 2.227829232475547e-06,
      "loss": 0.0008,
      "step": 8100
    },
    {
      "epoch": 3.2787721227877213,
      "grad_norm": 0.002709645312279463,
      "learning_rate": 2.008266805033341e-06,
      "loss": 0.0008,
      "step": 8200
    },
    {
      "epoch": 3.3187681231876813,
      "grad_norm": 0.003118810011073947,
      "learning_rate": 1.7988816927629327e-06,
      "loss": 0.0008,
      "step": 8300
    },
    {
      "epoch": 3.3587641235876413,
      "grad_norm": 0.00289492798037827,
      "learning_rate": 1.5999405434900017e-06,
      "loss": 0.0008,
      "step": 8400
    },
    {
      "epoch": 3.3987601239876013,
      "grad_norm": 0.003420450957491994,
      "learning_rate": 1.411696704858596e-06,
      "loss": 0.0008,
      "step": 8500
    },
    {
      "epoch": 3.4387561243875613,
      "grad_norm": 0.002510364865884185,
      "learning_rate": 1.23438990169788e-06,
      "loss": 0.0007,
      "step": 8600
    },
    {
      "epoch": 3.4787521247875213,
      "grad_norm": 0.0024526400957256556,
      "learning_rate": 1.0682459307372816e-06,
      "loss": 0.0007,
      "step": 8700
    },
    {
      "epoch": 3.5187481251874813,
      "grad_norm": 0.002159160329028964,
      "learning_rate": 9.13476373058787e-07,
      "loss": 0.0007,
      "step": 8800
    },
    {
      "epoch": 3.5587441255874412,
      "grad_norm": 0.0021331871394068003,
      "learning_rate": 7.702783246526002e-07,
      "loss": 0.0007,
      "step": 8900
    },
    {
      "epoch": 3.5987401259874012,
      "grad_norm": 0.0036624670028686523,
      "learning_rate": 6.38834145419266e-07,
      "loss": 0.0007,
      "step": 9000
    },
    {
      "epoch": 3.638736126387361,
      "grad_norm": 0.0019509077537804842,
      "learning_rate": 5.193112269379241e-07,
      "loss": 0.0007,
      "step": 9100
    },
    {
      "epoch": 3.678732126787321,
      "grad_norm": 0.002148218220099807,
      "learning_rate": 4.1186177929641524e-07,
      "loss": 0.0007,
      "step": 9200
    },
    {
      "epoch": 3.718728127187281,
      "grad_norm": 0.002403866034001112,
      "learning_rate": 3.166226372547376e-07,
      "loss": 0.0007,
      "step": 9300
    },
    {
      "epoch": 3.758724127587241,
      "grad_norm": 0.002211430110037327,
      "learning_rate": 2.3371508598866055e-07,
      "loss": 0.0007,
      "step": 9400
    },
    {
      "epoch": 3.798720127987201,
      "grad_norm": 0.0018155282596126199,
      "learning_rate": 1.6324470663543813e-07,
      "loss": 0.0007,
      "step": 9500
    },
    {
      "epoch": 3.838716128387161,
      "grad_norm": 0.003297098446637392,
      "learning_rate": 1.0530124183830593e-07,
      "loss": 0.0007,
      "step": 9600
    },
    {
      "epoch": 3.878712128787121,
      "grad_norm": 0.002821548841893673,
      "learning_rate": 5.995848146098881e-08,
      "loss": 0.0007,
      "step": 9700
    },
    {
      "epoch": 3.918708129187081,
      "grad_norm": 0.0020123326685279608,
      "learning_rate": 2.727416861776022e-08,
      "loss": 0.0007,
      "step": 9800
    },
    {
      "epoch": 3.9587041295870415,
      "grad_norm": 0.0022015157155692577,
      "learning_rate": 7.289926138721592e-09,
      "loss": 0.0007,
      "step": 9900
    },
    {
      "epoch": 3.998700129987001,
      "grad_norm": 0.003156330669298768,
      "learning_rate": 3.120356394270552e-11,
      "loss": 0.0007,
      "step": 10000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.00030405857251025736,
      "eval_macro_f1": 1.0,
      "eval_overall_accuracy": 1.0,
      "eval_overall_f1": 1.0,
      "eval_overall_precision": 1.0,
      "eval_overall_recall": 1.0,
      "eval_runtime": 89.5672,
      "eval_samples_per_second": 111.659,
      "eval_steps_per_second": 6.989,
      "step": 10004
    }
  ],
  "logging_steps": 100,
  "max_steps": 10004,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.741333623561168e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
